# Zoo Animal Classification Project
# A comprehensive machine learning project for classifying animals based on their characteristics

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import precision_score, recall_score, f1_score
import warnings
warnings.filterwarnings('ignore')

# Set style for plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("Zoo Animal Classification Project")
print("=" * 50)

# Load the datasets
print("\n1. Loading Data...")
try:
    # Load zoo data and class labels
    zoo_data = pd.read_csv('zoo.data', header=None)
    class_data = pd.read_csv('class.data', header=None)
    
    # Define column names for zoo data
    zoo_columns = [
        'animal_name', 'hair', 'feathers', 'eggs', 'milk', 'airborne', 'aquatic',
        'predator', 'toothed', 'backbone', 'breathes', 'venomous', 'fins',
        'legs', 'tail', 'domestic', 'catsize', 'class_type'
    ]
    
    # Define column names for class data
    class_columns = ['Class_Type', 'Number_Of_Animal_Species_In_Class', 'Class_Name', 'Animal_Names']
    
    zoo_data.columns = zoo_columns
    class_data.columns = class_columns
    
    print(f"Zoo data shape: {zoo_data.shape}")
    print(f"Class data shape: {class_data.shape}")
    
except FileNotFoundError:
    print("Data files not found. Please ensure zoo.data and class.data are in the same directory.")
    print("You can download them from: https://www.kaggle.com/datasets/uciml/zoo-animal-classification")

# Display basic information about the dataset
print("\n2. Dataset Overview")
print("-" * 30)
print("Zoo Data Info:")
print(zoo_data.info())

print("\nClass Data Info:")
print(class_data.info())

print("\nFirst 5 rows of Zoo Data:")
print(zoo_data.head())

print("\nFirst 5 rows of Class Data:")
print(class_data.head())

# Basic statistics
print("\n3. Basic Statistics")
print("-" * 30)
print("Zoo Data Statistics:")
print(zoo_data.describe())

print("\nClass Distribution:")
print(zoo_data['class_type'].value_counts().sort_index())

# Data Quality Check
print("\n4. Data Quality Assessment")
print("-" * 30)
print("Missing Values in Zoo Data:")
print(zoo_data.isnull().sum())

print("\nDuplicate Rows:")
print(f"Number of duplicate rows: {zoo_data.duplicated().sum()}")

print("\nData Types:")
print(zoo_data.dtypes)

# Exploratory Data Analysis
print("\n5. Exploratory Data Analysis")
print("-" * 30)

# Create visualizations
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Class distribution
axes[0, 0].pie(zoo_data['class_type'].value_counts().sort_index(), 
               labels=class_data['Class_Name'].values, autopct='%1.1f%%')
axes[0, 0].set_title('Distribution of Animal Classes')

# Correlation heatmap
numeric_features = zoo_data.select_dtypes(include=[np.number]).drop('class_type', axis=1)
correlation_matrix = numeric_features.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=axes[0, 1])
axes[0, 1].set_title('Feature Correlation Matrix')

# Feature distribution by class
feature_means = zoo_data.groupby('class_type')[numeric_features.columns].mean()
feature_means.plot(kind='bar', ax=axes[1, 0])
axes[1, 0].set_title('Average Feature Values by Class')
axes[1, 0].set_xlabel('Class Type')
axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')

# Legs distribution
zoo_data['legs'].value_counts().sort_index().plot(kind='bar', ax=axes[1, 1])
axes[1, 1].set_title('Distribution of Number of Legs')
axes[1, 1].set_xlabel('Number of Legs')

plt.tight_layout()
plt.show()

# Advanced EDA
print("\n6. Advanced Exploratory Analysis")
print("-" * 30)

# Feature importance analysis
features_by_class = zoo_data.groupby('class_type').agg({
    'hair': 'mean', 'feathers': 'mean', 'eggs': 'mean', 'milk': 'mean',
    'airborne': 'mean', 'aquatic': 'mean', 'predator': 'mean', 'toothed': 'mean',
    'backbone': 'mean', 'breathes': 'mean', 'venomous': 'mean', 'fins': 'mean',
    'tail': 'mean', 'domestic': 'mean', 'catsize': 'mean'
})

print("Feature averages by class:")
print(features_by_class.round(2))

# Create a more detailed visualization
fig, axes = plt.subplots(3, 2, figsize=(15, 18))

# Binary features analysis
binary_features = ['hair', 'feathers', 'eggs', 'milk', 'airborne', 'aquatic']
for i, feature in enumerate(binary_features):
    row, col = i // 2, i % 2
    cross_tab = pd.crosstab(zoo_data['class_type'], zoo_data[feature])
    cross_tab.plot(kind='bar', ax=axes[row, col])
    axes[row, col].set_title(f'{feature.capitalize()} by Class')
    axes[row, col].legend(['No', 'Yes'])

plt.tight_layout()
plt.show()

# 7. Feature Engineering
print("\n7. Feature Engineering")
print("-" * 30)

# Prepare features and target
X = zoo_data.drop(['animal_name', 'class_type'], axis=1)
y = zoo_data['class_type']

print(f"Feature matrix shape: {X.shape}")
print(f"Target vector shape: {y.shape}")

# Check for any remaining non-numeric data
print("\nFeature data types:")
print(X.dtypes)

# Create additional features
X['total_features'] = X.sum(axis=1)
X['mobility_score'] = X['legs'] + X['airborne'] + X['aquatic']
X['physical_traits'] = X['hair'] + X['feathers'] + X['tail'] + X['fins']

print(f"Enhanced feature matrix shape: {X.shape}")

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, 
                                                    random_state=42, stratify=y)

print(f"\nTraining set shape: {X_train.shape}")
print(f"Test set shape: {X_test.shape}")

# Scale features for algorithms that need it
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 8. Model Training and Evaluation
print("\n8. Model Training and Evaluation")
print("-" * 30)

# Initialize models
models = {
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Support Vector Machine': SVC(random_state=42),
    'Decision Tree': DecisionTreeClassifier(random_state=42),
    'Naive Bayes': GaussianNB()
}

# Train and evaluate models
results = {}

for name, model in models.items():
    print(f"\nTraining {name}...")
    
    # Use scaled data for models that benefit from it
    if name in ['Logistic Regression', 'Support Vector Machine', 'Naive Bayes']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        cv_scores = cross_val_score(model, X_train, y_train, cv=5)
    
    # Calculate metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    results[name] = {
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'CV Mean': cv_scores.mean(),
        'CV Std': cv_scores.std()
    }
    
    print(f"{name} - Accuracy: {accuracy:.4f}, CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

# Display results
print("\n9. Model Comparison")
print("-" * 30)
results_df = pd.DataFrame(results).T
print(results_df.round(4))

# Visualize results
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Accuracy comparison
results_df['Accuracy'].plot(kind='bar', ax=axes[0])
axes[0].set_title('Model Accuracy Comparison')
axes[0].set_ylabel('Accuracy')
axes[0].tick_params(axis='x', rotation=45)

# CV Score comparison
results_df['CV Mean'].plot(kind='bar', ax=axes[1])
axes[1].set_title('Cross-Validation Score Comparison')
axes[1].set_ylabel('CV Score')
axes[1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# 10. Best Model Analysis
print("\n10. Best Model Analysis")
print("-" * 30)

# Find best model
best_model_name = results_df['Accuracy'].idxmax()
best_model = models[best_model_name]

print(f"Best performing model: {best_model_name}")
print(f"Best accuracy: {results_df.loc[best_model_name, 'Accuracy']:.4f}")

# Retrain best model and get detailed results
if best_model_name in ['Logistic Regression', 'Support Vector Machine', 'Naive Bayes']:
    best_model.fit(X_train_scaled, y_train)
    y_pred_best = best_model.predict(X_test_scaled)
else:
    best_model.fit(X_train, y_train)
    y_pred_best = best_model.predict(X_test)

# Detailed classification report
print("\nDetailed Classification Report:")
print(classification_report(y_test, y_pred_best))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title(f'Confusion Matrix - {best_model_name}')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Feature importance (for tree-based models)
if hasattr(best_model, 'feature_importances_'):
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(10, 8))
    plt.barh(range(len(feature_importance)), feature_importance['importance'])
    plt.yticks(range(len(feature_importance)), feature_importance['feature'])
    plt.xlabel('Feature Importance')
    plt.title(f'Feature Importance - {best_model_name}')
    plt.gca().invert_yaxis()
    plt.tight_layout()
    plt.show()
    
    print("\nTop 10 Most Important Features:")
    print(feature_importance.head(10))

# 11. Hyperparameter Tuning
print("\n11. Hyperparameter Tuning")
print("-" * 30)

# Tune the best model
if best_model_name == 'Random Forest':
    param_grid = {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10]
    }
elif best_model_name == 'Gradient Boosting':
    param_grid = {
        'n_estimators': [50, 100, 200],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7]
    }
elif best_model_name == 'Support Vector Machine':
    param_grid = {
        'C': [0.1, 1, 10, 100],
        'kernel': ['linear', 'rbf', 'poly'],
        'gamma': ['scale', 'auto']
    }
else:
    param_grid = {}

if param_grid:
    print(f"Performing hyperparameter tuning for {best_model_name}...")
    
    grid_search = GridSearchCV(
        models[best_model_name], param_grid, cv=5, 
        scoring='accuracy', n_jobs=-1
    )
    
    if best_model_name in ['Logistic Regression', 'Support Vector Machine', 'Naive Bayes']:
        grid_search.fit(X_train_scaled, y_train)
        tuned_predictions = grid_search.predict(X_test_scaled)
    else:
        grid_search.fit(X_train, y_train)
        tuned_predictions = grid_search.predict(X_test)
    
    tuned_accuracy = accuracy_score(y_test, tuned_predictions)
    
    print(f"Best parameters: {grid_search.best_params_}")
    print(f"Tuned model accuracy: {tuned_accuracy:.4f}")
    print(f"Improvement: {tuned_accuracy - results_df.loc[best_model_name, 'Accuracy']:.4f}")

# 12. Final Model Interpretation
print("\n12. Final Model Interpretation")
print("-" * 30)

# Create class mapping for interpretation
class_mapping = dict(zip(class_data['Class_Type'], class_data['Class_Name']))
print("Class Mapping:")
for i, name in class_mapping.items():
    print(f"Class {i}: {name}")

# Sample predictions with explanations
print("\nSample Predictions:")
sample_indices = np.random.choice(X_test.index, 5, replace=False)

for idx in sample_indices:
    animal_name = zoo_data.loc[idx, 'animal_name']
    true_class = zoo_data.loc[idx, 'class_type']
    
    if best_model_name in ['Logistic Regression', 'Support Vector Machine', 'Naive Bayes']:
        sample_features = scaler.transform([X_test.loc[idx]])
        pred_class = best_model.predict(sample_features)[0]
    else:
        pred_class = best_model.predict([X_test.loc[idx]])[0]
    
    print(f"\nAnimal: {animal_name}")
    print(f"True Class: {true_class} ({class_mapping[true_class]})")
    print(f"Predicted Class: {pred_class} ({class_mapping[pred_class]})")
    print(f"Correct: {'✓' if true_class == pred_class else '✗'}")

print("\n" + "="*50)
print("PROJECT COMPLETED SUCCESSFULLY!")
print("="*50)
